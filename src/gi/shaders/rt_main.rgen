#extension GL_GOOGLE_include_directive: require
#extension GL_EXT_ray_tracing: require
#extension GL_EXT_control_flow_attributes: require

#include "rt_payload.glsl"
#include "rt_descriptors.glsl"

layout(location = 0) rayPayloadEXT RayPayload rayPayload;

vec3 evaluate_sample(inout uvec4 rng_state,
                     in vec3 ray_origin,
                     in vec3 ray_dir)
{
    rayPayload.rng_state  = rng_state;
    rayPayload.ray_origin = ray_origin;
    rayPayload.ray_dir    = ray_dir;
    rayPayload.throughput = vec3(1.0, 1.0, 1.0);
    rayPayload.radiance   = vec3(0.0, 0.0, 0.0);
    rayPayload.bitfield   = 0;

    [[loop]]
    while ((rayPayload.bitfield & 0x7FFFFFFFu) <= PC.MAX_BOUNCES)
    {
        traceRayEXT(
            sceneAS,               // top-level acceleration structure
            0,                     // rayFlags
            0xFF,                  // cullMask
            0,                     // sbtRecordOffset
            0,                     // sbtRecordStride
            0,                     // missIndex
            rayPayload.ray_origin, // ray origin
            0.0,                   // ray min range
            rayPayload.ray_dir,    // ray direction
            FLOAT_MAX,             // ray max range
            0                      // payload (location = 0)
        );
    }

#if AOV_ID == AOV_ID_DEBUG_BOUNCES
    return vec3(float(rayPayload.bitfield & 0x7FFFFFFFu), 0.0, 0.0);
#endif

    rng_state = rayPayload.rng_state; // FIXME: find cleaner solution

    return clamp(rayPayload.radiance, vec3(0.0, 0.0, 0.0), vec3(PC.MAX_SAMPLE_VALUE, PC.MAX_SAMPLE_VALUE, PC.MAX_SAMPLE_VALUE));
}

void main()
{
#if AOV_ID == AOV_ID_DEBUG_CLOCK_CYCLES
    uint64_t start_cycle_count = clockARB();
#endif

    uvec2 pixel_pos = gl_LaunchIDEXT.xy;
    uint pixel_index = pixel_pos.x + pixel_pos.y * PC.IMAGE_WIDTH;

    vec3 camera_right = cross(PC.CAMERA_FORWARD, PC.CAMERA_UP);
    float aspect_ratio = float(PC.IMAGE_WIDTH) / float(PC.IMAGE_HEIGHT);

    float H = 1.0;
    float W = H * aspect_ratio;
    float d = H / (2.0 * tan(PC.CAMERA_VFOV * 0.5));

    float WX = W / float(PC.IMAGE_WIDTH);
    float HY = H / float(PC.IMAGE_HEIGHT);

    vec3 C = PC.CAMERA_POSITION + PC.CAMERA_FORWARD * d;
    vec3 L = C - camera_right * W * 0.5 - PC.CAMERA_UP * H * 0.5;

    float inv_sample_count = 1.0 / float(PC.SAMPLE_COUNT);

    vec3 pixel_color = vec3(0.0, 0.0, 0.0);
    for (uint s = 0; s < PC.SAMPLE_COUNT; ++s)
    {
        uvec4 rng_state = pcg4d_init(pixel_pos.xy, PC.SAMPLE_OFFSET + s);
        vec4 r = pcg4d_next(rng_state);

        vec3 P =
            L +
            (float(pixel_pos.x) + r.x) * camera_right * WX +
            (float(pixel_pos.y) + r.y) * PC.CAMERA_UP * HY;

        vec3 ray_origin = PC.CAMERA_POSITION;
        vec3 ray_dir = P - ray_origin;

        /* Beware: a single direction component must not be zero,
         * because we often take the inverse of the direction. */
        ray_dir += vec3(equal(ray_dir, vec3(0.0))) * FLOAT_MIN;

        ray_dir = normalize(ray_dir);

        /* Path trace sample and accumulate color. */
        vec3 sample_color = evaluate_sample(rng_state, ray_origin, ray_dir);
        pixel_color += sample_color * inv_sample_count;
    }

#if AOV_ID == AOV_ID_DEBUG_CLOCK_CYCLES
    float cycles_elapsed_norm = float(clockARB() - start_cycle_count) / float(UINT32_MAX);
    pixel_color = vec3(cycles_elapsed_norm, 0.0, 0.0);
#endif

    if (PC.SAMPLE_OFFSET > 0)
    {
      float inv_total_sample_count = 1.0 / float(PC.SAMPLE_OFFSET + PC.SAMPLE_COUNT);

      float weight_old = float(PC.SAMPLE_OFFSET) * inv_total_sample_count;
      float weight_new = float(PC.SAMPLE_COUNT) * inv_total_sample_count;

      pixel_color = weight_old * pixels[pixel_index].rgb + weight_new * pixel_color;
    }

    pixels[pixel_index] = vec4(pixel_color, 0.0);
}
